What is W&B?

Weights & Biases is an MLOps tool for:
	â€¢	Experiment tracking
	â€¢	Hyperparameter sweeps
	â€¢	Collaboration (dashboards, reports)
	â€¢	Model management

Why W&B?

Without W&B:
	â€¢	Experiments are logged manually (hard to compare).
	â€¢	Sharing results across team is messy.

With W&B:
	â€¢	Centralized dashboard of runs.
	â€¢	Easy comparison of parameters/metrics.
	â€¢	Hyperparameter tuning at scale.

- pip install -r requirements.txt
- wandb login
- python train_wandb.py

ğŸ”¹ Key Difference in Practice
	â€¢	MLflow:
	â€¢	Run â†’ Compare runs â†’ Register model â†’ Deploy to prod.
	â€¢	Focus = operationalization.
	â€¢	W&B:
	â€¢	Run â†’ Visualize charts â†’ Share report â†’ Tune hyperparams.
	â€¢	Focus = collaboration + exploration.

â¸»

ğŸ”¹ Analogy
	â€¢	MLflow = like Docker + Jenkins â†’ package, version, deploy.
	â€¢	W&B = like Google Docs for ML experiments â†’ easy to share, comment, visualize.


ğŸ”¹ What are Hyperparameters?
	â€¢	Parameters you set before training, not learned from data.
	â€¢	Examples:
	â€¢	RandomForest â†’ n_estimators, max_depth
	â€¢	Neural nets â†’ learning_rate, batch_size, num_layers
	â€¢	XGBoost â†’ eta, max_depth, colsample_bytree

They strongly influence performance, but thereâ€™s no formula for the â€œbestâ€ values.

â¸»

ğŸ”¹ What is Hyperparameter Sweeping?

Itâ€™s the process of automatically training the model multiple times with different hyperparameter combinations to find the best-performing one.

Think of it as grid-searching or auto-tuning:
	â€¢	Try n_estimators=50, 100, 200
	â€¢	Try max_depth=3, 5, None
	â€¢	Evaluate each run â†’ pick the one with highest accuracy (or lowest loss).

â¸»

ğŸ”¹ Types of Sweeps
	1.	Grid Search â†’ try all possible combinations.
	    â€¢	    E.g., 3Ã—3 grid = 9 runs.
	    â€¢	Expensive but exhaustive.
	2.	Random Search â†’ pick random combinations.
	    â€¢	Cheaper, surprisingly effective.
	3.	Bayesian Optimization â†’ use past results to pick smarter next combinations.
	    â€¢	Efficient for large search spaces.
	4.	Hyperband / Population-based â†’ advanced methods for deep learning.

ğŸ”¹ The options
	1.	grid
	â€¢	Tries every possible combination of parameters.
	â€¢	Example:
	â€¢	n_estimators: [50, 100, 200]
	â€¢	max_depth: [5, 10]
	â€¢	â†’ 3 Ã— 2 = 6 runs total.
	â€¢	âœ… Exhaustive, good for small search spaces.
	â€¢	âŒ Expensive for large search spaces.

â¸»

	2.	random
	â€¢	Picks random combinations from parameter space.
	â€¢	Example: same grid as above â†’ instead of all 6, it might sample 4 random ones.
	â€¢	âœ… Efficient for large spaces.
	â€¢	âœ… Often finds good configs faster than grid.
	â€¢	âŒ Might miss the absolute best if unlucky.

â¸»

	3.	bayes (Bayesian optimization)
	â€¢	Uses results of previous runs to guide next hyperparameter choice.
	â€¢	Smarter than random, especially with continuous values (e.g., learning rate).
	â€¢	âœ… More sample-efficient.
	â€¢	âŒ Slower per-step (needs optimization overhead).


Check YAML file for the method.